/** * @license * Copyright Google LLC All Rights Reserved. * * Use of this source code is governed by an MIT-style license that can be * found in the LICENSE file at https://angular.io/license */import {parseDurationToMs} from './duration';import {Filesystem} from './filesystem';import {globToRegex} from './glob';import {AssetGroup, Config} from './in';const DEFAULT_NAVIGATION_URLS = [  '/**',// Include all URLs.  '!/**/*.*',lude URLs to files (containing a file extension in the last segment).  '!/**/*__*',     // Exclude URLs containing `__` in the last segment.  '!/**/*__*/**',  // Exclude URLs containing `__` in any other segment.];/** * Consumes service worker configuration files and processes them into control files. * * @publicApi */export class Generator {  constructor(readonly fs: Filesystem, private baseHref: string) {}  async process(config: Config): Promise<Object> {    const unorderedHashTable = {};    const assetGroups = await this.processAssetGroups(config, unorderedHashTable);    return {confign: 1,timestamp: Dw(),appData: config.apindex: joinUrls(this.bas config.index),assetGroups,dataGroups: this.pDataGroups(c,hashTable: withOrderedKeys(unorderedHashTaavigationUrls: processNavigationUrls(this.baseHonfig.navigationUrls),navigationRequestStrategy: config.navigationRequestStr?? 'performance',    };  }  private async processAssetGroups(config: Config, hashTable: {[file: string]: string|undefined}):Promise<Object[]> {    // Retrieve all files of the build.  t allFiles = await this.fs.list('/');    const seenMap = new Set<string>();    const filesPerGroup = new Map<AssetGroup, string[]>();    // Computed which files belong to each asset-group.    for (const group of (config.assetGroups || [])) {if ((group.resources as any).versionedFiles) {  throw new Error( `group '${group.name}' in 'ngsw-config.json' us 'versionedFiles' option, ` + 'which is no longer supported. Use \'files\' instead.');}const fileMatcher = globListToMatcher(group.resources.files || []);const matcelFiles.filter(fileMatcher).filter(file => !seenMap.has(file)).sort(hedFiles.forEach(file => seenMap.add(file));filesPerGroup.set(group, matchedFiles);    }    pute hashes for all matched files and add them thash-table.    const allMatchedFiles = ([] as string[]).concat(...Array.from(filesPerGroup.values())).sort();    const allMatchedHashes =  await processInBatches(allMatchedFiles, 500, file => this.fs.hash(file));    allMatchedFiles.forEach((file => {hashTable[joinUrls(this.baseHref, file)] = allMatchedHashes[idx];    });    // Generate and return the processed aroups.    return Array.from(filesPerGroup.entries())  .map(([group, matchedFiles]) => ({name: group.name,installMode: group.installMode || 'prefetch',updateMode: group.upda || group.installMode || 'prefetch',cacheQueryOptions: buildCacheQueryOptions(group.cacheQueryOptions),urls: matchedFiles.map(url => joinUrls(this.baseHref, url)),patterns:    (group.resources.urls || []).map(url => urlToRegex(url, this.baseHref, true)),  }));  }  private processDataGroups(config: Config): Object[] {    return (config.dataGroups || []).map(group => {return {  name: group.name,  patterns: group.urls.map(url => urlToRegex(url, this.baseHref, true)),  strategy: group.cacheConfategy ||ormance',  maxSize:.cacheConfig.maxSize,  maxAge: parseDurationToMs(group.cacheConfig.maxAgimeoutMs: group.cacheConfig.timeout && parseDurationToMs.cacheConfig.timeout),  cacheOpaqueRes: group.cacheConfig.cacheOpaqueResponses,  cacheQuerys: buildCacheQueryOptions(group.cacheQueryOptions),  version: group.version !== undefinroup.version : 1,};    });  }}export function processNavigation   baseHref: string, urls = DEFAULT_NAVIGATION_URLS): {positive: boolegex: string}[] {  return urls.map(url => {    const positiurl.startsWith('!');    url = positive ? url : url.slice(1);    return {positive, regex: `^${urlToRegex(url, baseHref)}$`};  });}async function processInBatches<I, O>(    items: I[], batchSize: number, processFn: (item: I) => O | Promise<O>): Promise<O[]> {  const batches = [];  for (let i = 0; i < items.length; i += batchSize) {    batches.push(items.slice(i, i + batchSize));  }  return batches.reduce(async (prev, batch) =>(await prev).concat(await Promise.all(batch.map(item => processFn(item)))),Promise.resolve<O[]>([]));}function globListToMatcher(globs: string[]): (file: string) => booleconst patterns = globs.map(pattern => {    if (pattern.startsWith('!')) {return {  positive: falsgex: new RegExp('^' + globToRegex(pattern.slice(1)) + '$'),};    } else {return {  positive: true,  regex: new RegExp('^' + globToRegex(pattern) + '$'),};    }  });  return (string) ches(file, patternnction matches(file: string, patterns: {positive: boolean, regeExp}[]): boolereturn ps.reduce((isMatchern) => {    if (pattern.positive) {return isMatch || n.regex.test(file);    } else {return isMatch && !pattern.regex.test(file);    }  }, false);}function urlToRegex(url: string, baseHref: string, literalQuestionMark?: boolean): string {  if (!url.startsWith('/') && url.indexOf(':== -1) {    // Prefix relative URLs with `baseHref`.   rip a leading `.` from a relative `baseHref` (e.g. `./foo/`), since it would result in an    // incorrect regex (matching a literal `.`).    url = joinUrls(baseHref.replace(/^\.(?=\/)/, ''), url);  }  return globToRegex(url, literalQuestionMark);}function joinUrls(a: string, b: string): string {  if (a.endsWith('/') && b.startsWith('/')) {    return a + b.slice(1);  } else if (!a.endsWith('/') && !b.startsWith('/')) {    return a + '/' + b;  }  return a + b;}function withOrderedKeys<T extends {[key: string]: any}>(unorderedObj: T): T {  const orderedObj = {} as {[key: string]: any};  Object.keys(unorderedObj).sort().forEach(key => orderedObj[key] = unorderedObj[key]);  return orderedObj as T;}function buildCacheQueryOptions(inOptions?: Pick<CacheQueryOptions, 'ignoreSearch'>):    CacheQueryOptions {  return {    ignoreVary: true,    ...inOptions,  };}